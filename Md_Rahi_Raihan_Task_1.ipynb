{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1jyKudBQpJ3b"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "def load_dataset(file_path):\n",
        "    return pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "JTMOcYqNupK2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore dataset\n",
        "def explore_dataset(df):\n",
        "    print(\"Dataset Overview:\")\n",
        "    display(df.head())\n",
        "    print(\"\\nDataset Information:\")\n",
        "    print(df.info())\n",
        "    print(\"\\nDataset Statistics:\")\n",
        "    print(df.describe())\n"
      ],
      "metadata": {
        "id": "TIotUsPGvJsD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter movies by genre, release year, or director\n",
        "def filter_movies(df, genre=None, year=None, director=None):\n",
        "    filtered_df = df\n",
        "    if genre:\n",
        "        filtered_df = filtered_df[filtered_df['Genre'].str.contains(genre, case=False, na=False)]\n",
        "    if year:\n",
        "        filtered_df = filtered_df[filtered_df['Release Year'] == year]\n",
        "    if director:\n",
        "        filtered_df = filtered_df[filtered_df['Director'].str.contains(director, case=False, na=False)]\n",
        "    return filtered_df"
      ],
      "metadata": {
        "id": "_y9P1sfBvMsx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Search movies by title or keywords\n",
        "def search_movies(df, query):\n",
        "    return df[df['Title'].str.contains(query, case=False, na=False) | df['Genre'].str.contains(query, case=False, na=False)]"
      ],
      "metadata": {
        "id": "COrf6cQivNUd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add user ratings and reviews\n",
        "def add_user_feedback(df, movie_id, user_rating, user_review):\n",
        "    if movie_id in df['Movie ID'].values:\n",
        "        df.loc[df['Movie ID'] == movie_id, 'Number of Votes'] += 1\n",
        "        current_rating = df.loc[df['Movie ID'] == movie_id, 'Rating'].values[0]\n",
        "        num_votes = df.loc[df['Movie ID'] == movie_id, 'Number of Votes'].values[0]\n",
        "        new_rating = (current_rating * (num_votes - 1) + user_rating) / num_votes\n",
        "        df.loc[df['Movie ID'] == movie_id, 'Rating'] = new_rating\n",
        "        df.loc[df['Movie ID'] == movie_id, 'User Reviews'] = df.loc[df['Movie ID'] == movie_id, 'User Reviews'].fillna('') + f\" {user_review}\"\n",
        "    else:\n",
        "        print(\"Movie ID not found.\")\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "oLexvW1CvTY6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate top 10 lists\n",
        "def generate_top_10(df, by, value=None):\n",
        "    if value:\n",
        "        filtered_df = filter_movies(df, genre=value) if by == 'Genre' else filter_movies(df, year=value)\n",
        "    else:\n",
        "        filtered_df = df\n",
        "    return filtered_df.sort_values(by='Rating', ascending=False).head(10)"
      ],
      "metadata": {
        "id": "Kjzo-sJUvXgE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize data\n",
        "def visualize_data(df):\n",
        "    # Rating distribution\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    df['Rating'].hist(bins=20, color='skyblue', edgecolor='black')\n",
        "    plt.title('Rating Distribution')\n",
        "    plt.xlabel('Rating')\n",
        "    plt.ylabel('Count')\n",
        "    plt.show()\n",
        "\n",
        "    # Movie counts per genre\n",
        "    genre_counts = df['Genre'].value_counts().head(10)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    genre_counts.plot(kind='bar', color='lightgreen')\n",
        "    plt.title('Top 10 Movie Genres')\n",
        "    plt.xlabel('Genre')\n",
        "    plt.ylabel('Count')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "14aqvQ-2vd8-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Interactive menu\n",
        "def interactive_menu():\n",
        "    print(\"\\nMovie Recommendation System\")\n",
        "    print(\"1. Load and explore dataset\")\n",
        "    print(\"2. Filter movies by genre, release year, or director\")\n",
        "    print(\"3. Search movies by title or keywords\")\n",
        "    print(\"4. Add ratings and reviews\")\n",
        "    print(\"5. Generate Top 10 lists\")\n",
        "    print(\"6. Visualize data\")\n",
        "    print(\"7. Exit\")\n"
      ],
      "metadata": {
        "id": "FcUgo8DTwncW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Mount Google Drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Specify the path to the dataset in your Google Drive\n",
        "    file_path = '/content/drive/My Drive/7_Movie_Recommendation_System.csv'  # Update this with the correct file path\n",
        "\n",
        "    # Load dataset\n",
        "    movies_df = load_dataset(file_path)\n",
        "\n",
        "    while True:\n",
        "        interactive_menu()\n",
        "        choice = input(\"Enter your choice: \")\n",
        "\n",
        "        if choice == '1':\n",
        "            explore_dataset(movies_df)\n",
        "        elif choice == '2':\n",
        "            genre = input(\"Enter genre (or press Enter to skip): \")\n",
        "            year = input(\"Enter release year (or press Enter to skip): \")\n",
        "            director = input(\"Enter director (or press Enter to skip): \")\n",
        "            year = int(year) if year else None\n",
        "            filtered = filter_movies(movies_df, genre, year, director)\n",
        "            display(filtered)\n",
        "        elif choice == '3':\n",
        "            query = input(\"Enter title or keyword to search: \")\n",
        "            results = search_movies(movies_df, query)\n",
        "            display(results)\n",
        "        elif choice == '4':\n",
        "            movie_id = int(input(\"Enter Movie ID: \"))\n",
        "            user_rating = float(input(\"Enter your rating (0-5): \"))\n",
        "            user_review = input(\"Enter your review: \")\n",
        "            movies_df = add_user_feedback(movies_df, movie_id, user_rating, user_review)\n",
        "        elif choice == '5':\n",
        "            by = input(\"Generate Top 10 by (Genre/Year): \").capitalize()\n",
        "            value = input(\"Enter value (or press Enter to skip): \")\n",
        "            top_10 = generate_top_10(movies_df, by, value)\n",
        "            display(top_10)\n",
        "        elif choice == '6':\n",
        "            visualize_data(movies_df)\n",
        "        elif choice == '7':\n",
        "            print(\"Exiting program. Goodbye!\")\n",
        "            break\n",
        "        else:\n",
        "            print(\"Invalid choice. Please try again.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "mHrv4Ffpwrn1",
        "outputId": "0ba7ed19-ca24-4a88-a3a8-3b7bb428feaa"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "Error tokenizing data. C error: Expected 8 fields in line 33, saw 9\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-2738f0dfca3f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmovies_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-b9f8b3b36375>\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1921\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 8 fields in line 33, saw 9\n"
          ]
        }
      ]
    }
  ]
}